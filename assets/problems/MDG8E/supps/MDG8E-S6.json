{
    "Directions": "Read the passage. Then answer each question that follows.",
    "Context": [],
    "Title": "[from] “Am I Human?”",
    "Subtitle": "",
    "Author": "by Gary Marcus",
    "LabelType": "P",
    "Content": [
        ["1", "In 1950 Alan Turing devised a thought experiment that has since been revered as the ultimate test of machine intelligence. He called it the “imitation game,” but most people know it as the Turing test. Anticipating what we now call chat bots— computer programs that masquerade as humans— Turing envisioned a contest in which a machine tries to trick an interrogator into believing it is human, answering questions about poetry and deliberately making mistakes about arithmetic. Today, in the eyes of the general public, the Turing test is often seen as a kind of a Rubicon, a measure of whether machines have truly arrived. But it shouldn't be: the Rubicon can be passed, though for the wrong reasons. It is now possible to build machines that fool people, at least for brief periods— but the victories are fleeting, and they do not seem to be carrying us even close to genuine intelligence."],
        ["2", "The problem is that Turing's test is too easily gamed. One can “win” simply by being deceptive or feigning ignorance. As Turing himself partly anticipated, the trick to winning is mostly not to answer the questions. If a judge asks a machine, “Do you have feelings?” the machine must lie to win. But that odd twist is not an exception— it is the rule. The way to win the Turing test is to deceive."],
        ["3", "In 2014, for example, a chat bot named “Eugene Goostman” supposedly “won” the Turing test by pretending to be a sarcastic 13- year- old boy from Odessa, Ukraine, who never answered questions directly. Some judges were fooled (about a third, enough to count as a shallow victory). But so what? The judges got only a few minutes to conduct their interviews, and they undoubtedly would have ferreted out the truth soon enough. In reality, Eugene knew— and understood— almost nothing. Consider this dialogue, which computer scientist Scott Aaronson had with the bot:"],
        [" ", "SCOTT:\nWhich is bigger, a shoebox or Mount Everest?\n\nEUGENE:\nI can't make a choice right now. I should think it out later. And I forgot to ask you where you are from ...\n\nSCOTT:\nHow many legs does a camel have?\n\nEUGENE:\nSomething between 2 and 4. Maybe, three? :-))) By the way, I still don't know your specialty— or, possibly, I've missed it?\n\nSCOTT:\nHow many legs does a millipede have?\n\nEUGENE:\nJust two, but Chernobyl mutants may have them up to five. I know you are supposed to trick me.\n\nSCOTT:\nNo, I need to know that you're not a chatbot. Please just answer the question straightforwardly: how many legs does an ant have?\n\nEUGENE:\nSomething between 2 and 4. Maybe, three? :-))) Oh, what a fruitful conversation ;-)."],
        ["4", "Clearly, Turing's original test has not withstood the test of time."]
    ],
    "Copyright": "“Am I Human?” from Scientific American by Gary Marcus. Copyright March 2017 by Scientific American, a Division of Springer Nature America, Inc. Reproduced with permission of Scientific American, a Division of Springer Nature America, Inc. via Copyright Clearance Center.",
    "References": []
}